{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('original\\\\UPDATED_NLP_COURSE\\\\06-Deep-Learning\\\\train_qa.txt','rb') as f:\n",
    "    train_data = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('original\\\\UPDATED_NLP_COURSE\\\\06-Deep-Learning\\\\test_qa.txt','rb') as f:\n",
    "    test_data = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Mary moved to the bathroom . Sandra journeyed to the bedroom .'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "' '.join(train_data[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = test_data + train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11000"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = set()\n",
    "\n",
    "for story, question, answer in all_data:\n",
    "    vocab = vocab.union(set(story))\n",
    "    vocab = vocab.union(set(question))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab.add('yes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab.add('no')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "37"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'.',\n",
       " '?',\n",
       " 'Daniel',\n",
       " 'Is',\n",
       " 'John',\n",
       " 'Mary',\n",
       " 'Sandra',\n",
       " 'apple',\n",
       " 'back',\n",
       " 'bathroom',\n",
       " 'bedroom',\n",
       " 'discarded',\n",
       " 'down',\n",
       " 'dropped',\n",
       " 'football',\n",
       " 'garden',\n",
       " 'got',\n",
       " 'grabbed',\n",
       " 'hallway',\n",
       " 'in',\n",
       " 'journeyed',\n",
       " 'kitchen',\n",
       " 'left',\n",
       " 'milk',\n",
       " 'moved',\n",
       " 'no',\n",
       " 'office',\n",
       " 'picked',\n",
       " 'put',\n",
       " 'the',\n",
       " 'there',\n",
       " 'to',\n",
       " 'took',\n",
       " 'travelled',\n",
       " 'up',\n",
       " 'went',\n",
       " 'yes'}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_len = len(vocab) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "38"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Longest Story\n",
    "all_story_length = [len(data[0]) for data in all_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_story_len = max(all_story_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "156"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_story_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_question_length = [len(data[1]) for data in all_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_question_length = max(all_question_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_question_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.preprocessing.text import Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(filters=[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.fit_on_texts(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'.': 1,\n",
       " 'dropped': 2,\n",
       " 'is': 3,\n",
       " 'in': 4,\n",
       " 'bathroom': 5,\n",
       " '?': 6,\n",
       " 'john': 7,\n",
       " 'moved': 8,\n",
       " 'travelled': 9,\n",
       " 'bedroom': 10,\n",
       " 'put': 11,\n",
       " 'daniel': 12,\n",
       " 'picked': 13,\n",
       " 'discarded': 14,\n",
       " 'kitchen': 15,\n",
       " 'to': 16,\n",
       " 'up': 17,\n",
       " 'there': 18,\n",
       " 'no': 19,\n",
       " 'milk': 20,\n",
       " 'went': 21,\n",
       " 'journeyed': 22,\n",
       " 'the': 23,\n",
       " 'football': 24,\n",
       " 'yes': 25,\n",
       " 'got': 26,\n",
       " 'grabbed': 27,\n",
       " 'left': 28,\n",
       " 'hallway': 29,\n",
       " 'garden': 30,\n",
       " 'back': 31,\n",
       " 'down': 32,\n",
       " 'sandra': 33,\n",
       " 'apple': 34,\n",
       " 'took': 35,\n",
       " 'office': 36,\n",
       " 'mary': 37}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_story_text = []\n",
    "train_question_text = []\n",
    "train_answer_text = []\n",
    "for story, question, answer in train_data:\n",
    "    train_story_text.append(story)\n",
    "    train_question_text.append(question)\n",
    "    train_answer_text.append(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_story_seq = tokenizer.texts_to_sequences(train_story_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#len(train_story_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorize_stories(data, word_index = tokenizer.word_index, max_story_len = max_story_len, max_question_length = max_question_length):\n",
    "    #stories\n",
    "    X = []\n",
    "    #Questions\n",
    "    Xq = []\n",
    "    #Answers\n",
    "    Y = []\n",
    "    \n",
    "    for story, question,answer in data:\n",
    "        x = [word_index[word.lower()] for word in story]\n",
    "        xq = [word_index[word.lower()] for word in question]\n",
    "        \n",
    "        y = np.zeros(len(word_index)+1)\n",
    "        \n",
    "        y[word_index[answer]] = 1\n",
    "        \n",
    "        X.append(x)\n",
    "        Xq.append(xq)\n",
    "        Y.append(y)\n",
    "        \n",
    "    return (pad_sequences(X,maxlen=max_story_len),pad_sequences(Xq,maxlen=max_question_length),np.array(Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_train, question_train, answer_train = vectorize_stories(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_test, question_test, answer_test = vectorize_stories(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0., 503., 497.])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(answer_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Model, Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers.embeddings import Embedding\n",
    "from keras.layers import Input, Activation, Dense, Permute, Dropout, add, dot, concatenate, LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PLACEHOLDER shape = (max_story, batch_size)\n",
    "input_sequence = Input((max_story_len,))\n",
    "question = Input((max_question_length,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([Dimension(None), Dimension(156)])"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_sequence.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = len(vocab) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "#INPUT ENCODER\n",
    "input_encoder_m = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Gaurav\\Anaconda3\\envs\\nlp_course\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From C:\\Users\\Gaurav\\Anaconda3\\envs\\nlp_course\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    }
   ],
   "source": [
    "input_encoder_m.add(Embedding(input_dim=vocab_size, output_dim=64))\n",
    "input_encoder_m.add(Dropout(0.3))\n",
    "\n",
    "#OUTPUT\n",
    "#(samples, story_maxlen, embedding_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "#INPUTE ENCODER C\n",
    "input_encoder_c = Sequential()\n",
    "input_encoder_c.add(Embedding(input_dim=vocab_size,output_dim=max_question_length))\n",
    "input_encoder_c.add(Dropout(0.3))\n",
    "\n",
    "#OUTPUT (samples, story_maxlen, max_quest_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Question ENCODER\n",
    "question_encoder = Sequential()\n",
    "question_encoder.add(Embedding(input_dim=vocab_size,output_dim=64,input_length=max_question_length))\n",
    "question_encoder.add(Dropout(0.3))\n",
    "\n",
    "#OUTPUT  (samples, query_maxlen, embedding_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_encoded_m = input_encoder_m(input_sequence)\n",
    "input_encoded_c = input_encoder_c(input_sequence)\n",
    "question_encoded = question_encoder(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "match = dot([input_encoded_m, question_encoded],axes=(2,2))\n",
    "match = Activation('softmax')(match)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = add([match,input_encoded_c])\n",
    "response = Permute((2,1))(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "answer = concatenate([response,question_encoded])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'concatenate_1/concat:0' shape=(?, 6, 220) dtype=float32>"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "answer = LSTM(32)(answer)\n",
    "answer = Dropout(0.5)(answer)\n",
    "answer = Dense(vocab_size)(answer) #(samples, vocav_size) YES/NO 0000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "answer = Activation('softmax')(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model([input_sequence,question],answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='rmsprop',loss='categorical_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 156)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            (None, 6)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "sequential_1 (Sequential)       multiple             2432        input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "sequential_3 (Sequential)       (None, 6, 64)        2432        input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dot_1 (Dot)                     (None, 156, 6)       0           sequential_1[1][0]               \n",
      "                                                                 sequential_3[1][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 156, 6)       0           dot_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "sequential_2 (Sequential)       multiple             228         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 156, 6)       0           activation_1[0][0]               \n",
      "                                                                 sequential_2[1][0]               \n",
      "__________________________________________________________________________________________________\n",
      "permute_1 (Permute)             (None, 6, 156)       0           add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 6, 220)       0           permute_1[0][0]                  \n",
      "                                                                 sequential_3[1][0]               \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   (None, 32)           32384       concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 32)           0           lstm_1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 38)           1254        dropout_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 38)           0           dense_1[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 38,730\n",
      "Trainable params: 38,730\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 156)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Gaurav\\Anaconda3\\envs\\nlp_course\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "WARNING:tensorflow:From C:\\Users\\Gaurav\\Anaconda3\\envs\\nlp_course\\lib\\site-packages\\tensorflow\\python\\ops\\math_grad.py:102: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Deprecated in favor of operator or tf.math.divide.\n",
      "Train on 10000 samples, validate on 1000 samples\n",
      "Epoch 1/100\n",
      "10000/10000 [==============================] - 12s 1ms/step - loss: 0.8829 - acc: 0.4920 - val_loss: 0.7022 - val_acc: 0.4970\n",
      "Epoch 2/100\n",
      "10000/10000 [==============================] - 9s 907us/step - loss: 0.7040 - acc: 0.4935 - val_loss: 0.6944 - val_acc: 0.4970\n",
      "Epoch 3/100\n",
      "10000/10000 [==============================] - 9s 878us/step - loss: 0.6956 - acc: 0.5010 - val_loss: 0.6959 - val_acc: 0.4970\n",
      "Epoch 4/100\n",
      "10000/10000 [==============================] - 8s 757us/step - loss: 0.6955 - acc: 0.4968 - val_loss: 0.6934 - val_acc: 0.4970\n",
      "Epoch 5/100\n",
      "10000/10000 [==============================] - 8s 843us/step - loss: 0.6949 - acc: 0.4972 - val_loss: 0.6937 - val_acc: 0.4970 0.6946 - \n",
      "Epoch 6/100\n",
      "10000/10000 [==============================] - 8s 796us/step - loss: 0.6945 - acc: 0.4988 - val_loss: 0.6946 - val_acc: 0.4970\n",
      "Epoch 7/100\n",
      "10000/10000 [==============================] - 8s 809us/step - loss: 0.6950 - acc: 0.4988 - val_loss: 0.6957 - val_acc: 0.4970\n",
      "Epoch 8/100\n",
      "10000/10000 [==============================] - 8s 761us/step - loss: 0.6943 - acc: 0.4963 - val_loss: 0.6938 - val_acc: 0.5030\n",
      "Epoch 9/100\n",
      "10000/10000 [==============================] - 8s 799us/step - loss: 0.6942 - acc: 0.5019 - val_loss: 0.6940 - val_acc: 0.50306944 - ac\n",
      "Epoch 10/100\n",
      "10000/10000 [==============================] - 8s 763us/step - loss: 0.6950 - acc: 0.4973 - val_loss: 0.6937 - val_acc: 0.5030\n",
      "Epoch 11/100\n",
      "10000/10000 [==============================] - 8s 787us/step - loss: 0.6942 - acc: 0.4976 - val_loss: 0.6933 - val_acc: 0.4940\n",
      "Epoch 12/100\n",
      "10000/10000 [==============================] - 8s 765us/step - loss: 0.6928 - acc: 0.5071 - val_loss: 0.6925 - val_acc: 0.5040\n",
      "Epoch 13/100\n",
      "10000/10000 [==============================] - 8s 763us/step - loss: 0.6862 - acc: 0.5353 - val_loss: 0.6795 - val_acc: 0.5630\n",
      "Epoch 14/100\n",
      "10000/10000 [==============================] - 8s 819us/step - loss: 0.6627 - acc: 0.6040 - val_loss: 0.6390 - val_acc: 0.6490\n",
      "Epoch 15/100\n",
      "10000/10000 [==============================] - 8s 839us/step - loss: 0.6350 - acc: 0.6397 - val_loss: 0.6173 - val_acc: 0.6580\n",
      "Epoch 16/100\n",
      "10000/10000 [==============================] - 9s 899us/step - loss: 0.6249 - acc: 0.6561 - val_loss: 0.6132 - val_acc: 0.6660\n",
      "Epoch 17/100\n",
      "10000/10000 [==============================] - 11s 1ms/step - loss: 0.6181 - acc: 0.6619 - val_loss: 0.6230 - val_acc: 0.6630\n",
      "Epoch 18/100\n",
      "10000/10000 [==============================] - 12s 1ms/step - loss: 0.6108 - acc: 0.6670 - val_loss: 0.5936 - val_acc: 0.6880\n",
      "Epoch 19/100\n",
      "10000/10000 [==============================] - 12s 1ms/step - loss: 0.5958 - acc: 0.6860 - val_loss: 0.5758 - val_acc: 0.6990\n",
      "Epoch 20/100\n",
      "10000/10000 [==============================] - ETA: 0s - loss: 0.5782 - acc: 0.700 - 11s 1ms/step - loss: 0.5783 - acc: 0.7004 - val_loss: 0.5603 - val_acc: 0.7090\n",
      "Epoch 21/100\n",
      "10000/10000 [==============================] - 10s 1ms/step - loss: 0.5586 - acc: 0.7088 - val_loss: 0.5325 - val_acc: 0.7280\n",
      "Epoch 22/100\n",
      "10000/10000 [==============================] - 11s 1ms/step - loss: 0.5422 - acc: 0.7300 - val_loss: 0.5105 - val_acc: 0.7400\n",
      "Epoch 23/100\n",
      "10000/10000 [==============================] - 11s 1ms/step - loss: 0.5305 - acc: 0.7335 - val_loss: 0.5034 - val_acc: 0.7470\n",
      "Epoch 24/100\n",
      "10000/10000 [==============================] - 13s 1ms/step - loss: 0.5194 - acc: 0.7418 - val_loss: 0.4757 - val_acc: 0.7940\n",
      "Epoch 25/100\n",
      "10000/10000 [==============================] - 17s 2ms/step - loss: 0.4985 - acc: 0.7652 - val_loss: 0.4556 - val_acc: 0.8020\n",
      "Epoch 26/100\n",
      "10000/10000 [==============================] - 13s 1ms/step - loss: 0.4731 - acc: 0.7803 - val_loss: 0.4564 - val_acc: 0.8020\n",
      "Epoch 27/100\n",
      "10000/10000 [==============================] - 12s 1ms/step - loss: 0.4698 - acc: 0.7827 - val_loss: 0.4321 - val_acc: 0.8120\n",
      "Epoch 28/100\n",
      "10000/10000 [==============================] - 11s 1ms/step - loss: 0.4469 - acc: 0.8001 - val_loss: 0.4395 - val_acc: 0.7990\n",
      "Epoch 29/100\n",
      "10000/10000 [==============================] - 11s 1ms/step - loss: 0.4443 - acc: 0.7995 - val_loss: 0.4167 - val_acc: 0.8090\n",
      "Epoch 30/100\n",
      "10000/10000 [==============================] - 10s 979us/step - loss: 0.4374 - acc: 0.7966 - val_loss: 0.4504 - val_acc: 0.7900\n",
      "Epoch 31/100\n",
      "10000/10000 [==============================] - 11s 1ms/step - loss: 0.4304 - acc: 0.8020 - val_loss: 0.4349 - val_acc: 0.8030\n",
      "Epoch 32/100\n",
      "10000/10000 [==============================] - 10s 1ms/step - loss: 0.4239 - acc: 0.8078 - val_loss: 0.4289 - val_acc: 0.8050\n",
      "Epoch 33/100\n",
      "10000/10000 [==============================] - 10s 976us/step - loss: 0.4183 - acc: 0.8141 - val_loss: 0.4191 - val_acc: 0.8050acc: 0.\n",
      "Epoch 34/100\n",
      "10000/10000 [==============================] - 11s 1ms/step - loss: 0.4196 - acc: 0.8098 - val_loss: 0.4258 - val_acc: 0.8010\n",
      "Epoch 35/100\n",
      "10000/10000 [==============================] - 10s 1ms/step - loss: 0.4127 - acc: 0.8122 - val_loss: 0.4119 - val_acc: 0.8160\n",
      "Epoch 36/100\n",
      "10000/10000 [==============================] - 10s 971us/step - loss: 0.4133 - acc: 0.8113 - val_loss: 0.4278 - val_acc: 0.7950\n",
      "Epoch 37/100\n",
      "10000/10000 [==============================] - 10s 1ms/step - loss: 0.4058 - acc: 0.8125 - val_loss: 0.4083 - val_acc: 0.8060\n",
      "Epoch 38/100\n",
      "10000/10000 [==============================] - 10s 969us/step - loss: 0.4054 - acc: 0.8094 - val_loss: 0.4142 - val_acc: 0.8070\n",
      "Epoch 39/100\n",
      "10000/10000 [==============================] - 11s 1ms/step - loss: 0.4056 - acc: 0.8117 - val_loss: 0.4103 - val_acc: 0.8100\n",
      "Epoch 40/100\n",
      "10000/10000 [==============================] - 11s 1ms/step - loss: 0.3941 - acc: 0.8187 - val_loss: 0.4445 - val_acc: 0.7970\n",
      "Epoch 41/100\n",
      "10000/10000 [==============================] - 10s 1ms/step - loss: 0.3987 - acc: 0.8202 - val_loss: 0.4122 - val_acc: 0.8070\n",
      "Epoch 42/100\n",
      "10000/10000 [==============================] - 11s 1ms/step - loss: 0.3859 - acc: 0.8261 - val_loss: 0.4246 - val_acc: 0.8060\n",
      "Epoch 43/100\n",
      "10000/10000 [==============================] - 11s 1ms/step - loss: 0.3862 - acc: 0.8229 - val_loss: 0.4039 - val_acc: 0.8090\n",
      "Epoch 44/100\n",
      "10000/10000 [==============================] - 10s 981us/step - loss: 0.3829 - acc: 0.8240 - val_loss: 0.4155 - val_acc: 0.8050\n",
      "Epoch 45/100\n",
      "10000/10000 [==============================] - 11s 1ms/step - loss: 0.3784 - acc: 0.8270 - val_loss: 0.4064 - val_acc: 0.8120\n",
      "Epoch 46/100\n",
      "10000/10000 [==============================] - 11s 1ms/step - loss: 0.3774 - acc: 0.8267 - val_loss: 0.4015 - val_acc: 0.8150\n",
      "Epoch 47/100\n",
      "10000/10000 [==============================] - 10s 976us/step - loss: 0.3747 - acc: 0.8292 - val_loss: 0.4098 - val_acc: 0.8090\n",
      "Epoch 48/100\n",
      "10000/10000 [==============================] - 11s 1ms/step - loss: 0.3701 - acc: 0.8299 - val_loss: 0.4067 - val_acc: 0.8120\n",
      "Epoch 49/100\n",
      "10000/10000 [==============================] - 10s 1ms/step - loss: 0.3681 - acc: 0.8305 - val_loss: 0.4105 - val_acc: 0.8050\n",
      "Epoch 50/100\n",
      "10000/10000 [==============================] - 9s 929us/step - loss: 0.3658 - acc: 0.8334 - val_loss: 0.4043 - val_acc: 0.8040\n",
      "Epoch 51/100\n",
      "10000/10000 [==============================] - 10s 970us/step - loss: 0.3627 - acc: 0.8364 - val_loss: 0.4131 - val_acc: 0.8000\n",
      "Epoch 52/100\n",
      "10000/10000 [==============================] - 8s 835us/step - loss: 0.3595 - acc: 0.8368 - val_loss: 0.4126 - val_acc: 0.8100\n",
      "Epoch 53/100\n",
      "10000/10000 [==============================] - 8s 830us/step - loss: 0.3557 - acc: 0.8366 - val_loss: 0.4081 - val_acc: 0.8090\n",
      "Epoch 54/100\n",
      "10000/10000 [==============================] - 8s 839us/step - loss: 0.3588 - acc: 0.8346 - val_loss: 0.4079 - val_acc: 0.8100\n",
      "Epoch 55/100\n",
      "10000/10000 [==============================] - 8s 780us/step - loss: 0.3506 - acc: 0.8405 - val_loss: 0.4189 - val_acc: 0.8100\n",
      "Epoch 56/100\n",
      "10000/10000 [==============================] - 7s 742us/step - loss: 0.3524 - acc: 0.8389 - val_loss: 0.4348 - val_acc: 0.8060\n",
      "Epoch 57/100\n",
      "10000/10000 [==============================] - 8s 783us/step - loss: 0.3456 - acc: 0.8396 - val_loss: 0.4136 - val_acc: 0.8030\n",
      "Epoch 58/100\n",
      "10000/10000 [==============================] - 7s 749us/step - loss: 0.3434 - acc: 0.8425 - val_loss: 0.4313 - val_acc: 0.8100\n",
      "Epoch 59/100\n",
      "10000/10000 [==============================] - 8s 805us/step - loss: 0.3460 - acc: 0.8417 - val_loss: 0.4635 - val_acc: 0.8010\n",
      "Epoch 60/100\n",
      "10000/10000 [==============================] - ETA: 0s - loss: 0.3442 - acc: 0.8459- ETA: - ETA: 2s - loss: 0.3460 - ac - 8s 784us/step - loss: 0.3442 - acc: 0.8459 - val_loss: 0.4230 - val_acc: 0.8020\n",
      "Epoch 61/100\n",
      "10000/10000 [==============================] - 8s 786us/step - loss: 0.3354 - acc: 0.8456 - val_loss: 0.4211 - val_acc: 0.7980\n",
      "Epoch 62/100\n",
      "10000/10000 [==============================] - 8s 760us/step - loss: 0.3416 - acc: 0.8461 - val_loss: 0.4182 - val_acc: 0.8040\n",
      "Epoch 63/100\n",
      "10000/10000 [==============================] - 8s 799us/step - loss: 0.3339 - acc: 0.8461 - val_loss: 0.4420 - val_acc: 0.8010\n",
      "Epoch 64/100\n",
      "10000/10000 [==============================] - 8s 751us/step - loss: 0.3367 - acc: 0.8474 - val_loss: 0.4218 - val_acc: 0.8070\n",
      "Epoch 65/100\n",
      "10000/10000 [==============================] - 8s 810us/step - loss: 0.3338 - acc: 0.8502 - val_loss: 0.4346 - val_acc: 0.8070\n",
      "Epoch 66/100\n",
      "10000/10000 [==============================] - 7s 747us/step - loss: 0.3269 - acc: 0.8524 - val_loss: 0.4431 - val_acc: 0.8040\n",
      "Epoch 67/100\n",
      "10000/10000 [==============================] - 8s 835us/step - loss: 0.3263 - acc: 0.8541 - val_loss: 0.4465 - val_acc: 0.8020\n",
      "Epoch 68/100\n",
      "10000/10000 [==============================] - 7s 749us/step - loss: 0.3284 - acc: 0.8535 - val_loss: 0.4620 - val_acc: 0.7930\n",
      "Epoch 69/100\n",
      "10000/10000 [==============================] - 8s 838us/step - loss: 0.3229 - acc: 0.8507 - val_loss: 0.4795 - val_acc: 0.7910\n",
      "Epoch 70/100\n",
      "10000/10000 [==============================] - 7s 746us/step - loss: 0.3246 - acc: 0.8502 - val_loss: 0.4462 - val_acc: 0.7960\n",
      "Epoch 71/100\n",
      "10000/10000 [==============================] - 8s 810us/step - loss: 0.3137 - acc: 0.8568 - val_loss: 0.4574 - val_acc: 0.8000\n",
      "Epoch 72/100\n",
      "10000/10000 [==============================] - 8s 773us/step - loss: 0.3195 - acc: 0.8519 - val_loss: 0.4627 - val_acc: 0.8010\n",
      "Epoch 73/100\n",
      "10000/10000 [==============================] - 8s 832us/step - loss: 0.3109 - acc: 0.8593 - val_loss: 0.4628 - val_acc: 0.7990\n",
      "Epoch 74/100\n",
      "10000/10000 [==============================] - 8s 763us/step - loss: 0.3136 - acc: 0.8563 - val_loss: 0.4777 - val_acc: 0.8000\n",
      "Epoch 75/100\n",
      "10000/10000 [==============================] - 8s 819us/step - loss: 0.3120 - acc: 0.8600 - val_loss: 0.4788 - val_acc: 0.7950\n",
      "Epoch 76/100\n",
      "10000/10000 [==============================] - 8s 758us/step - loss: 0.3101 - acc: 0.8586 - val_loss: 0.4697 - val_acc: 0.7990\n",
      "Epoch 77/100\n",
      "10000/10000 [==============================] - 9s 915us/step - loss: 0.3033 - acc: 0.8650 - val_loss: 0.4939 - val_acc: 0.7920\n",
      "Epoch 78/100\n",
      "10000/10000 [==============================] - 8s 758us/step - loss: 0.3073 - acc: 0.8589 - val_loss: 0.4889 - val_acc: 0.7960\n",
      "Epoch 79/100\n",
      "10000/10000 [==============================] - 8s 827us/step - loss: 0.3043 - acc: 0.8622 - val_loss: 0.5037 - val_acc: 0.7940\n",
      "Epoch 80/100\n",
      "10000/10000 [==============================] - 8s 778us/step - loss: 0.3088 - acc: 0.8615 - val_loss: 0.4647 - val_acc: 0.7980\n",
      "Epoch 81/100\n",
      "10000/10000 [==============================] - 8s 829us/step - loss: 0.3008 - acc: 0.8663 - val_loss: 0.5057 - val_acc: 0.8020\n",
      "Epoch 82/100\n",
      "10000/10000 [==============================] - 8s 784us/step - loss: 0.2998 - acc: 0.8643 - val_loss: 0.5021 - val_acc: 0.7950\n",
      "Epoch 83/100\n",
      "10000/10000 [==============================] - 8s 833us/step - loss: 0.3015 - acc: 0.8679 - val_loss: 0.4900 - val_acc: 0.8010\n",
      "Epoch 84/100\n",
      "10000/10000 [==============================] - 8s 762us/step - loss: 0.2958 - acc: 0.8650 - val_loss: 0.4999 - val_acc: 0.7860\n",
      "Epoch 85/100\n",
      "10000/10000 [==============================] - 9s 871us/step - loss: 0.3010 - acc: 0.8661 - val_loss: 0.4687 - val_acc: 0.7990\n",
      "Epoch 86/100\n",
      "10000/10000 [==============================] - 8s 823us/step - loss: 0.2940 - acc: 0.8674 - val_loss: 0.4921 - val_acc: 0.7950\n",
      "Epoch 87/100\n",
      "10000/10000 [==============================] - 9s 876us/step - loss: 0.2948 - acc: 0.8671 - val_loss: 0.5265 - val_acc: 0.7920\n",
      "Epoch 88/100\n",
      "10000/10000 [==============================] - 7s 750us/step - loss: 0.3000 - acc: 0.8663 - val_loss: 0.5136 - val_acc: 0.7930\n",
      "Epoch 89/100\n",
      "10000/10000 [==============================] - 8s 840us/step - loss: 0.2949 - acc: 0.8658 - val_loss: 0.4880 - val_acc: 0.7890\n",
      "Epoch 90/100\n",
      "10000/10000 [==============================] - 8s 755us/step - loss: 0.2885 - acc: 0.8718 - val_loss: 0.5162 - val_acc: 0.7910\n",
      "Epoch 91/100\n",
      "10000/10000 [==============================] - 9s 851us/step - loss: 0.2896 - acc: 0.8706 - val_loss: 0.5183 - val_acc: 0.7890\n",
      "Epoch 92/100\n",
      "10000/10000 [==============================] - 8s 761us/step - loss: 0.2920 - acc: 0.8704 - val_loss: 0.4801 - val_acc: 0.7840\n",
      "Epoch 93/100\n",
      "10000/10000 [==============================] - 8s 845us/step - loss: 0.2839 - acc: 0.8761 - val_loss: 0.4973 - val_acc: 0.7930\n",
      "Epoch 94/100\n",
      "10000/10000 [==============================] - 8s 795us/step - loss: 0.2883 - acc: 0.8698 - val_loss: 0.5140 - val_acc: 0.7870\n",
      "Epoch 95/100\n",
      "10000/10000 [==============================] - 10s 958us/step - loss: 0.2819 - acc: 0.8737 - val_loss: 0.5016 - val_acc: 0.7900\n",
      "Epoch 96/100\n",
      "10000/10000 [==============================] - 10s 1ms/step - loss: 0.2821 - acc: 0.8740 - val_loss: 0.4869 - val_acc: 0.7960\n",
      "Epoch 97/100\n",
      "10000/10000 [==============================] - 22s 2ms/step - loss: 0.2840 - acc: 0.8750 - val_loss: 0.5035 - val_acc: 0.7940\n",
      "Epoch 98/100\n",
      "10000/10000 [==============================] - 17s 2ms/step - loss: 0.2765 - acc: 0.8758 - val_loss: 0.5072 - val_acc: 0.7960\n",
      "Epoch 99/100\n",
      "10000/10000 [==============================] - 14s 1ms/step - loss: 0.2816 - acc: 0.8712 - val_loss: 0.5027 - val_acc: 0.8010\n",
      "Epoch 100/100\n",
      "10000/10000 [==============================] - 15s 1ms/step - loss: 0.2776 - acc: 0.8757 - val_loss: 0.5366 - val_acc: 0.7930\n"
     ]
    }
   ],
   "source": [
    "# train\n",
    "history = model.fit([input_train, question_train], answer_train,batch_size=32,epochs=100,validation_data=([input_test, question_test], answer_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No handles with labels found to put in legend.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x21039fb9288>"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('chatbotmodel.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_result = model.predict(([input_test,question_test]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Mary',\n",
       " 'got',\n",
       " 'the',\n",
       " 'milk',\n",
       " 'there',\n",
       " '.',\n",
       " 'John',\n",
       " 'moved',\n",
       " 'to',\n",
       " 'the',\n",
       " 'bedroom',\n",
       " '.']"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 38)"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_result.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.53493822e-14, 1.41967237e-14, 1.43516113e-14, 1.46084842e-14,\n",
       "       1.47556138e-14, 1.36015738e-14, 1.41527372e-14, 1.47915703e-14,\n",
       "       1.45014920e-14, 1.39592546e-14, 1.52667524e-14, 1.39803567e-14,\n",
       "       1.49672992e-14, 1.53901601e-14, 1.27283861e-14, 1.35278895e-14,\n",
       "       1.36318840e-14, 1.36532470e-14, 1.34680314e-14, 1.45987060e-14,\n",
       "       1.18159453e-14, 1.34934864e-14, 1.44929201e-14, 1.41734294e-14,\n",
       "       1.32723863e-14, 1.30338601e-14, 1.39282701e-14, 1.52901543e-14,\n",
       "       1.38276045e-14, 1.23966169e-14, 1.49522898e-14, 1.54712160e-14,\n",
       "       1.38880013e-14, 1.29135492e-14, 1.53790385e-14, 1.33208518e-14,\n",
       "       9.98858094e-01, 1.14195724e-03], dtype=float32)"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_result[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_max = np.argmax(pred_result[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, val in tokenizer.word_index.items():\n",
    "    if val == val_max:\n",
    "        k = key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'no'"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9988581"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_result[0][val_max]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'.',\n",
       " '?',\n",
       " 'Daniel',\n",
       " 'Is',\n",
       " 'John',\n",
       " 'Mary',\n",
       " 'Sandra',\n",
       " 'apple',\n",
       " 'back',\n",
       " 'bathroom',\n",
       " 'bedroom',\n",
       " 'discarded',\n",
       " 'down',\n",
       " 'dropped',\n",
       " 'football',\n",
       " 'garden',\n",
       " 'got',\n",
       " 'grabbed',\n",
       " 'hallway',\n",
       " 'in',\n",
       " 'journeyed',\n",
       " 'kitchen',\n",
       " 'left',\n",
       " 'milk',\n",
       " 'moved',\n",
       " 'no',\n",
       " 'office',\n",
       " 'picked',\n",
       " 'put',\n",
       " 'the',\n",
       " 'there',\n",
       " 'to',\n",
       " 'took',\n",
       " 'travelled',\n",
       " 'up',\n",
       " 'went',\n",
       " 'yes'}"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_story = 'John left the kitchen . Sandra dropped the football in the garden .'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['John',\n",
       " 'left',\n",
       " 'the',\n",
       " 'kitchen',\n",
       " '.',\n",
       " 'Sandra',\n",
       " 'dropped',\n",
       " 'the',\n",
       " 'football',\n",
       " 'in',\n",
       " 'the',\n",
       " 'garden',\n",
       " '.']"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_story.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_question = 'Is the football in the garden ?'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Is', 'the', 'football', 'in', 'the', 'garden', '?']"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_question.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_data = [[my_story.split(),my_question.split(),'yes']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[['John',\n",
       "   'left',\n",
       "   'the',\n",
       "   'kitchen',\n",
       "   '.',\n",
       "   'Sandra',\n",
       "   'dropped',\n",
       "   'the',\n",
       "   'football',\n",
       "   'in',\n",
       "   'the',\n",
       "   'garden',\n",
       "   '.'],\n",
       "  ['Is', 'the', 'football', 'in', 'the', 'garden', '?'],\n",
       "  'yes']]"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_story, my_question, my_answer = vectorize_stories(my_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  7,\n",
       "        32,  2, 15,  1,  5, 29,  2, 21, 34,  2, 18,  1]])"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_story"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_result = model.predict(([my_story,my_question]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_max = np.argmax(pred_result[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "37"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, val in tokenizer.word_index.items():\n",
    "    if val == val_max:\n",
    "        k = key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'yes'"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.72423255"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_result[0][val_max]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
